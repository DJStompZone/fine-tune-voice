{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## An attempt to autonomously annotate many hours of raw training data.\n",
        "> ### What could *possibly* go wrong?\n",
        "\n"
      ],
      "metadata": {
        "id": "I3gFT6hPFH60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Configuration\n",
        "input_audio = \"trainingdata_01_02_25_postprocess.wav\" # @param {type:\"string\"}\n",
        "output_dir = \"transcriptions\" # @param {type:\"string\"}\n",
        "whisper_model = \"large\" # @param [\"tiny\", \"base\", \"small\", \"medium\", \"large\"]"
      ],
      "metadata": {
        "id": "pRV2S-KuF2l9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# connect google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import shutil\n",
        "shutil.copyfile(f\"/content/drive/MyDrive/{input_audio}\", input_audio)"
      ],
      "metadata": {
        "id": "aE-OApXsd6Oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Install Dependencies\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install ffmpeg-python pydub tqdm ipyfilechooser"
      ],
      "metadata": {
        "id": "2n1ID694Ffp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Imports\n",
        "import os\n",
        "import whisper\n",
        "from tqdm import tqdm\n",
        "from pydub import AudioSegment\n",
        "import random\n",
        "import math"
      ],
      "metadata": {
        "id": "1suwRsZ8Gdu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yspxLe0bE9lw"
      },
      "outputs": [],
      "source": [
        "# @title Setup\n",
        "# Friendly reminder üòÅ\n",
        "INPUT_AUDIO = input_audio\n",
        "if INPUT_AUDIO.startswith(\"H\") and not os.path.exists(INPUT_AUDIO):\n",
        "    print(f\"{INPUT_AUDIO} :D\")\n",
        "OUTPUT_DIR = f\"./{output_dir}/\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Loading Whisper model ({whisper_model})...\")\n",
        "model = whisper.load_model(whisper_model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Function Definitions\n",
        "# @markdown ## `split_audio` Function\n",
        "# Fruit ninja, but for data...\n",
        "# And without the fruit. Or the ninjas.\n",
        "# ...What was I talking about again?\n",
        "def split_audio(file_path, min_length_sec=5, max_length_sec=15):\n",
        "    \"\"\"\n",
        "    Splits a long audio file into smaller chunks suitable for TTS fine-tuning.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the input audio file.\n",
        "        min_length_sec (int): Minimum chunk length in seconds.\n",
        "        max_length_sec (int): Maximum chunk length in seconds.\n",
        "\n",
        "    Returns:\n",
        "        List of chunk file paths.\n",
        "    \"\"\"\n",
        "    print(f\"Splitting {file_path} into {min_length_sec}-{max_length_sec} second chunks...\")\n",
        "    audio = AudioSegment.from_file(file_path)\n",
        "    duration = len(audio) # In milliseconds\n",
        "    chunk_paths = []\n",
        "    start_ms = 0\n",
        "\n",
        "    while start_ms < duration:\n",
        "        # There's no way using random here will haunt me later :)\n",
        "        chunk_length = random.randint(min_length_sec * 1000, max_length_sec * 1000)\n",
        "        # It's fine. It's probably fine.\n",
        "        end_ms = min(start_ms + chunk_length, duration)\n",
        "\n",
        "        chunk = audio[start_ms:end_ms]\n",
        "        if len(chunk) >= min_length_sec * 1000:\n",
        "            chunk_path = os.path.join(OUTPUT_DIR, f\"chunk_{start_ms // 1000:05d}.mp3\")\n",
        "            chunk.export(chunk_path, format=\"mp3\")\n",
        "            chunk_paths.append(chunk_path)\n",
        "\n",
        "        start_ms = end_ms\n",
        "\n",
        "    print(f\"Split into {len(chunk_paths)} chunks.\")\n",
        "    # It's fine.\n",
        "    return chunk_paths\n",
        "\n",
        "# @markdown ## `transcribe_chunks` Function\n",
        "# Write that down! Write that down!\n",
        "def transcribe_chunks(chunk_paths, model, output_dir):\n",
        "    \"\"\"\n",
        "    Transcribes audio chunks using OpenAI Whisper.\n",
        "\n",
        "    Args:\n",
        "        chunk_paths (list): List of audio chunk file paths.\n",
        "        model (whisper.Model): Pre-loaded Whisper model.\n",
        "        output_dir (str): Directory to save transcriptions.\n",
        "    \"\"\"\n",
        "    print(\"Transcribing audio chunks...\")\n",
        "    for chunk_path in tqdm(chunk_paths):\n",
        "        result = model.transcribe(chunk_path)\n",
        "\n",
        "        transcription_path = os.path.join(output_dir, os.path.basename(chunk_path).replace(\".mp3\", \".txt\"))\n",
        "        with open(transcription_path, \"w\") as f:\n",
        "            f.write(result[\"text\"])\n",
        "\n",
        "        segments_path = os.path.join(output_dir, os.path.basename(chunk_path).replace(\".mp3\", \"_segments.txt\"))\n",
        "        with open(segments_path, \"w\") as f:\n",
        "            for segment in result[\"segments\"]:\n",
        "                f.write(f\"[{segment['start']:.2f} - {segment['end']:.2f}]: {segment['text']}\\n\")\n",
        "    print(\"Transcription complete.\")\n",
        "\n",
        "# @markdown ## `combine_transcriptions` Function\n",
        "def combine_transcriptions(output_dir, combined_file=\"combined_transcription.txt\"):\n",
        "    \"\"\"\n",
        "    Combines all transcription files into one.\n",
        "\n",
        "    \"The gods forced him to roll an immense boulder up a hill only for it to roll back down every time it neared the top, repeating this action for eternity.\"\n",
        "\n",
        "    Args:\n",
        "        output_dir (str): Directory containing transcription files.\n",
        "        combined_file (str): Output file for combined transcription.\n",
        "    \"\"\"\n",
        "    print(\"Combining transcriptions...\")\n",
        "    transcription_files = sorted([f for f in os.listdir(output_dir) if f.endswith(\".txt\") and \"_segments\" not in f])\n",
        "    combined_path = os.path.join(output_dir, combined_file)\n",
        "    with open(combined_path, \"w\") as combined:\n",
        "        for file in transcription_files:\n",
        "            file_path = os.path.join(output_dir, file)\n",
        "            with open(file_path, \"r\") as f:\n",
        "                combined.write(f.read() + \"\\n\")\n",
        "    print(f\"Combined transcription saved to {combined_path}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "WSqYgpn-GiOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Split the Audio\n",
        "chunk_paths = split_audio(INPUT_AUDIO)"
      ],
      "metadata": {
        "id": "jBsxYnBjGu7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Transcribe Chunks\n",
        "# Mmm. Chunky style.\n",
        "transcribe_chunks(chunk_paths, model, OUTPUT_DIR)"
      ],
      "metadata": {
        "id": "2ozYrd4AGw-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Combine Transcriptions\n",
        "combine_transcriptions(OUTPUT_DIR)"
      ],
      "metadata": {
        "id": "xGA-vw0bGzOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the entire transcriptions folder to google drive\n",
        "os.makedirs(f\"/content/drive/MyDrive/{output_dir}\", exist_ok=True)\n",
        "shutil.copytree(OUTPUT_DIR, f\"/content/drive/MyDrive/{output_dir}\", dirs_exist_ok=True)"
      ],
      "metadata": {
        "id": "aGtM_qAEfHX_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}